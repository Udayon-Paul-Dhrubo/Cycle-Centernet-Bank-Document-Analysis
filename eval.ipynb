{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def dbscan_result_to_aligned_result(result, threshold=0.5):\n",
    "    aligned_result = []\n",
    "\n",
    "    for boxes in result:\n",
    "        confident_boxes = boxes[boxes[:, 4] > threshold]\n",
    "        if confident_boxes.shape[0] > 0:\n",
    "            count_confident_boxes = confident_boxes.shape[0]\n",
    "\n",
    "            updated_confident_boxes = pd.DataFrame(confident_boxes, columns=[\"x1\", \"y1\", \"x2\", \"y2\", \"confidance\"])\n",
    "\n",
    "            X = confident_boxes[:, [0, 2]].flatten(order=\"F\")\n",
    "            Y = confident_boxes[:, [1, 3]].flatten(order=\"F\")\n",
    "\n",
    "            X_scaled = MinMaxScaler().fit_transform(X.reshape((-1, 1)))\n",
    "            Y_scaled = MinMaxScaler().fit_transform(Y.reshape((-1, 1)))\n",
    "\n",
    "            min_samples = int(np.sqrt(count_confident_boxes) / 2)\n",
    "            if min_samples < 2:\n",
    "                min_samples = 2\n",
    "            # print(\"min_samples = \", min_samples)\n",
    "            clustering_X = DBSCAN(eps=0.01, min_samples=min_samples).fit_predict(X_scaled)\n",
    "            clustering_Y = DBSCAN(eps=0.01, min_samples=min_samples).fit_predict(Y_scaled)\n",
    "\n",
    "            labels_X = set(clustering_X)\n",
    "            labels_Y = set(clustering_Y)\n",
    "\n",
    "            updated_confident_boxes[\"label_x1\"] = clustering_X[:count_confident_boxes]\n",
    "            updated_confident_boxes[\"label_y1\"] = clustering_Y[:count_confident_boxes]\n",
    "            updated_confident_boxes[\"label_x2\"] = clustering_X[count_confident_boxes:]\n",
    "            updated_confident_boxes[\"label_y2\"] = clustering_Y[count_confident_boxes:]\n",
    "\n",
    "            updated_confident_boxes[\"x1_upd\"] = 0\n",
    "            updated_confident_boxes[\"y1_upd\"] = 0\n",
    "            updated_confident_boxes[\"x2_upd\"] = 0\n",
    "            updated_confident_boxes[\"y2_upd\"] = 0\n",
    "\n",
    "            # img = Image.open(img_path)\n",
    "            # draw = ImageDraw.Draw(img)\n",
    "            # colors = [(255, 0, 0), (255, 255, 0), (255, 0, 255)]\n",
    "            # width = 5\n",
    "\n",
    "            x_correct = []\n",
    "            y_correct = []\n",
    "            for x in labels_X:\n",
    "                if x != -1:\n",
    "                    x_mean = int(np.mean(X[np.array(clustering_X) == x]))\n",
    "                    x_correct.append(x_mean)\n",
    "\n",
    "                    updated_confident_boxes.loc[updated_confident_boxes[\"label_x1\"] == x, \"x1_upd\"] = x_mean\n",
    "                    updated_confident_boxes.loc[updated_confident_boxes[\"label_x2\"] == x, \"x2_upd\"] = x_mean\n",
    "            for y in labels_Y:\n",
    "                if y != -1:\n",
    "                    y_mean = int(np.mean(Y[np.array(clustering_Y) == y]))\n",
    "                    y_correct.append(y_mean)\n",
    "\n",
    "                    updated_confident_boxes.loc[updated_confident_boxes[\"label_y1\"] == y, \"y1_upd\"] = y_mean\n",
    "                    updated_confident_boxes.loc[updated_confident_boxes[\"label_y2\"] == y, \"y2_upd\"] = y_mean\n",
    "\n",
    "            # for x in labels_X:\n",
    "            #     if x != -1:\n",
    "            #         x_mean = int(np.mean(X[np.array(clustering_X) == x]))\n",
    "            #         endpoints = (x_mean, max(y_correct)), (x_mean, min(y_correct))\n",
    "            #         draw.line(endpoints, fill=colors[0], width=width)\n",
    "            # for y in labels_Y:\n",
    "            #     if y != -1:\n",
    "            #         y_mean = int(np.mean(Y[np.array(clustering_Y) == y]))\n",
    "            #         endpoints = (max(x_correct), y_mean), (min(x_correct), y_mean)\n",
    "            #         draw.line(endpoints, fill=colors[0], width=width)\n",
    "\n",
    "            # print(f\"sorted_confident_x = {sorted(x_correct)}\")\n",
    "            # print(f\"sorted_confident_y = {sorted(y_correct)}\")\n",
    "\n",
    "            # img.save(\"/home/aiarhipov/centernet/imgs/output_lines.jpg\")\n",
    "            res = updated_confident_boxes[[\"x1_upd\", \"y1_upd\", \"x2_upd\", \"y2_upd\", \"confidance\"]].to_numpy()\n",
    "            res = res[(res[:, 0] < res[:, 2]) & (res[:, 1] < res[:, 3])]\n",
    "            aligned_result.append(res)\n",
    "\n",
    "    return aligned_result\n",
    "\n",
    "\n",
    "\n",
    "def algo2_result_to_aligned_result(\n",
    "    result,\n",
    "    r=0.1,\n",
    "    dist_thresh=30,\n",
    "    threshold=0.5,\n",
    "):\n",
    "    aligned_result = []\n",
    "\n",
    "    for boxes in result:\n",
    "        confident_boxes = boxes[boxes[:, 4] > threshold]\n",
    "\n",
    "        refined_boxes = set()\n",
    "        # confident_boxes = confident_boxes.copy()\n",
    "        for i, cell in enumerate(confident_boxes):\n",
    "            w_cell = cell[2] - cell[0]\n",
    "            h_cell = cell[3] - cell[1]\n",
    "            for v_i, (x_i, y_i) in enumerate(\n",
    "                (\n",
    "                    (cell[0], cell[1]),\n",
    "                    (cell[2], cell[1]),\n",
    "                    (cell[2], cell[3]),\n",
    "                    (cell[0], cell[3]),\n",
    "                )\n",
    "            ):\n",
    "                x_offset1 = max(w_cell * r, 4.0)\n",
    "                y_offset1 = max(h_cell * r, 4.0)\n",
    "\n",
    "                keep_x = []\n",
    "                keep_y = []\n",
    "                idx_i_j = []\n",
    "                vertex_idx = []\n",
    "\n",
    "                for j, another_cell in enumerate(confident_boxes):\n",
    "                    if i != j:\n",
    "                        x_offset2 = max((another_cell[2] - another_cell[0]) * r, 4.0)\n",
    "                        y_offset2 = max((another_cell[3] - another_cell[1]) * r, 4.0)\n",
    "\n",
    "                        for v_j, (x_j, y_j) in enumerate(\n",
    "                            (\n",
    "                                (another_cell[0], another_cell[1]),\n",
    "                                (another_cell[2], another_cell[1]),\n",
    "                                (another_cell[2], another_cell[3]),\n",
    "                                (another_cell[0], another_cell[3]),\n",
    "                            )\n",
    "                        ):\n",
    "                            xdist = abs(x_j - x_i)\n",
    "                            ydist = abs(y_j - y_i)\n",
    "                            dist = np.sqrt(xdist**2 + ydist**2)\n",
    "\n",
    "                            if not (\n",
    "                                xdist > x_offset1\n",
    "                                or xdist > x_offset2\n",
    "                                or ydist > y_offset1\n",
    "                                or ydist > y_offset2\n",
    "                                or dist > dist_thresh\n",
    "                            ):\n",
    "                                keep_x.append(x_j)\n",
    "                                keep_y.append(y_j)\n",
    "                                idx_i_j.append(j)\n",
    "                                vertex_idx.append(v_j)\n",
    "\n",
    "                            # if (\n",
    "                            #     i == 62\n",
    "                            #     and v_i == 0\n",
    "                            #     and j == 60\n",
    "                            #     and v_j == 1\n",
    "                            #     or j == 62\n",
    "                            #     and v_j == 0\n",
    "                            #     and i == 60\n",
    "                            #     and v_i == 1\n",
    "                            # ):\n",
    "                            #     print(\n",
    "                            #         f\"i = {i}, j = {j}, v_i = {v_i}, v_j = {v_j}\"\n",
    "                            #     )\n",
    "                            # print(\"h_cell = \", h_cell)\n",
    "                            # print(\"w_cell = \", w_cell)\n",
    "                            # print(\"cell[2] - cell[0] \", cell[2] - cell[0])\n",
    "                            # print(\"cell[3] - cell[1] \", cell[3] - cell[1])\n",
    "                            # print(\"xdist < x_offset1   \", xdist, x_offset1)\n",
    "                            # print(\"xdist < x_offset2   \", xdist, x_offset2)\n",
    "                            # print(\"ydist < y_offset1   \", ydist, y_offset1)\n",
    "                            # print(\"ydist < y_offset2   \", ydist, y_offset2)\n",
    "                            # print(\"dist  < dist_thresh \", dist, dist_thresh)\n",
    "                # if keep_x:\n",
    "                keep_x.append(x_i)\n",
    "                keep_y.append(y_i)\n",
    "                idx_i_j.append(i)\n",
    "                vertex_idx.append(v_i)\n",
    "\n",
    "                mean_x = int(np.mean(keep_x))\n",
    "                mean_y = int(np.mean(keep_y))\n",
    "\n",
    "                # print(f\"keep_x = {keep_x},  mean = {mean_x} \")\n",
    "                # print(f\"keep_y = {keep_y},  mean = {mean_y} \")\n",
    "                # print(\"idx_i_j = \", idx_i_j)\n",
    "                # print(\"vertex_idx = \", vertex_idx)\n",
    "                # print(\"#\" * 100)\n",
    "                # print(confident_boxes.shape)\n",
    "\n",
    "                # if 60 in idx_i_j or 62 in idx_i_j:\n",
    "                #     print(\"keep_x = \", keep_x)\n",
    "                #     print(\"keep_y = \", keep_y)\n",
    "                #     print(\"idx_i_j = \", idx_i_j)\n",
    "                #     print(\"vertex_idx = \", vertex_idx)\n",
    "                #     print(\"#\" * 100)\n",
    "\n",
    "                for idx, v_idx in zip(idx_i_j, vertex_idx):\n",
    "                    refined_boxes.add(int(str(v_idx) + str(idx)))\n",
    "                    if v_idx == 0:\n",
    "                        confident_boxes[idx, 0] = mean_x\n",
    "                        confident_boxes[idx, 1] = mean_y\n",
    "                    elif v_idx == 1:\n",
    "                        confident_boxes[idx, 2] = mean_x\n",
    "                        confident_boxes[idx, 1] = mean_y\n",
    "                    elif v_idx == 2:\n",
    "                        confident_boxes[idx, 2] = mean_x\n",
    "                        confident_boxes[idx, 3] = mean_y\n",
    "                    elif v_idx == 3:\n",
    "                        confident_boxes[idx, 0] = mean_x\n",
    "                        confident_boxes[idx, 3] = mean_y\n",
    "                    else:\n",
    "                        pass\n",
    "                        # print(f\"strange vertex idx{idx}\")\n",
    "\n",
    "        aligned_result.append(confident_boxes)\n",
    "\n",
    "        # print(\"refined_boxes = \", refined_boxes)\n",
    "        # print(\"len refined_boxes = \", len(refined_boxes))\n",
    "    return aligned_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = '/media/quadro/NVME/Mehrab/Current_Experiment/config.py'\n",
    "checkpoint_file = '/media/quadro/NVME/Mehrab/exps/32_quad_long_retry/latest.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quadro/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from mmdet.apis import init_detector, inference_detector, show_result_pyplot\n",
    "import mmcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: /media/quadro/NVME/Mehrab/exps/32_quad_long_retry/latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-20 15:20:45,225 - root - INFO - ModulatedDeformConvPack neck.deconv_layers.0.conv is upgraded to version 2.\n",
      "2024-01-20 15:20:45,249 - root - INFO - ModulatedDeformConvPack neck.deconv_layers.2.conv is upgraded to version 2.\n",
      "2024-01-20 15:20:45,274 - root - INFO - ModulatedDeformConvPack neck.deconv_layers.4.conv is upgraded to version 2.\n"
     ]
    }
   ],
   "source": [
    "model = init_detector(config_file, checkpoint_file, device='cuda:3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/media/quadro/NVME/Mehrab/bank_statement.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3000, 9]) torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = (5400, 5) batch_labels = (3000,)\n",
      "bbboxes shape  (5400, 5)\n",
      "labels shape  (3000,)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Lengths of bboxes and labels must match",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43minference_detector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/quadro/NVME/Mehrab/Current_Experiment/mmdet/apis/inference.py:151\u001b[0m, in \u001b[0;36minference_detector\u001b[0;34m(model, imgs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# forward the model\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 151\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreturn_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrescale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_batch:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/media/quadro/NVME/afnan/conda/openmmlab/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m/media/quadro/NVME/afnan/conda/openmmlab/lib/python3.8/site-packages/mmcv/runner/fp16_utils.py:116\u001b[0m, in \u001b[0;36mauto_fp16.<locals>.auto_fp16_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m@auto_fp16 can only be used to decorate the \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    114\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmethod of those classes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_types\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfp16_enabled\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mfp16_enabled):\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mold_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# get the arg spec of the decorated method\u001b[39;00m\n\u001b[1;32m    119\u001b[0m args_info \u001b[38;5;241m=\u001b[39m getfullargspec(old_func)\n",
      "File \u001b[0;32m/media/quadro/NVME/Mehrab/Current_Experiment/mmdet/models/detectors/base.py:174\u001b[0m, in \u001b[0;36mBaseDetector.forward\u001b[0;34m(self, img, img_metas, return_loss, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_train(img, img_metas, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_metas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/quadro/NVME/Mehrab/Current_Experiment/mmdet/models/detectors/base.py:147\u001b[0m, in \u001b[0;36mBaseDetector.forward_test\u001b[0;34m(self, imgs, img_metas, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproposals\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    146\u001b[0m         kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproposals\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproposals\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimple_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_metas\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m imgs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maug test does not support \u001b[39m\u001b[38;5;124m'\u001b[39m \\\n\u001b[1;32m    150\u001b[0m                                  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minference with batch size \u001b[39m\u001b[38;5;124m'\u001b[39m \\\n\u001b[1;32m    151\u001b[0m                                  \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimgs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m/media/quadro/NVME/Mehrab/Current_Experiment/mmdet/models/detectors/single_stage.py:91\u001b[0m, in \u001b[0;36mSingleStageDetector.simple_test\u001b[0;34m(self, img, img_metas, rescale)\u001b[0m\n\u001b[1;32m     89\u001b[0m feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_feat(img)\n\u001b[1;32m     90\u001b[0m results_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbbox_head\u001b[38;5;241m.\u001b[39msimple_test(feat, img_metas, rescale\u001b[38;5;241m=\u001b[39mrescale)\n\u001b[0;32m---> 91\u001b[0m bbox_results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     92\u001b[0m     bbox2result(det_bboxes, det_labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbbox_head\u001b[38;5;241m.\u001b[39mnum_classes)\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m det_bboxes, det_labels \u001b[38;5;129;01min\u001b[39;00m results_list\n\u001b[1;32m     94\u001b[0m ]\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bbox_results\n",
      "File \u001b[0;32m/media/quadro/NVME/Mehrab/Current_Experiment/mmdet/models/detectors/single_stage.py:92\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     89\u001b[0m feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_feat(img)\n\u001b[1;32m     90\u001b[0m results_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbbox_head\u001b[38;5;241m.\u001b[39msimple_test(feat, img_metas, rescale\u001b[38;5;241m=\u001b[39mrescale)\n\u001b[1;32m     91\u001b[0m bbox_results \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 92\u001b[0m     \u001b[43mbbox2result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdet_bboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdet_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbbox_head\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m det_bboxes, det_labels \u001b[38;5;129;01min\u001b[39;00m results_list\n\u001b[1;32m     94\u001b[0m ]\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bbox_results\n",
      "File \u001b[0;32m/media/quadro/NVME/Mehrab/Current_Experiment/mmdet/core/bbox/transforms.py:140\u001b[0m, in \u001b[0;36mbbox2result\u001b[0;34m(bboxes, labels, num_classes)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels shape \u001b[39m\u001b[38;5;124m\"\u001b[39m , labels\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# Reshape bboxes\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# bboxes = bboxes.reshape(labels.shape[0], -1)  #[:, :5]\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m bboxes \u001b[38;5;241m=\u001b[39m \u001b[43mreshape_bboxes_based_on_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbboxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbboxes shape \u001b[39m\u001b[38;5;124m\"\u001b[39m , bboxes\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels shape \u001b[39m\u001b[38;5;124m\"\u001b[39m , labels\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/media/quadro/NVME/Mehrab/Current_Experiment/mmdet/core/bbox/transforms.py:149\u001b[0m, in \u001b[0;36mreshape_bboxes_based_on_labels\u001b[0;34m(bboxes, labels)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape_bboxes_based_on_labels\u001b[39m(bboxes, labels):\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;66;03m# Ensure that the lengths match\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(bboxes) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLengths of bboxes and labels must match\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;66;03m# Initialize an empty array to store reshaped bounding boxes\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     reshaped_bboxes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((\u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;241m5\u001b[39m))\n",
      "\u001b[0;31mAssertionError\u001b[0m: Lengths of bboxes and labels must match"
     ]
    }
   ],
   "source": [
    "res = inference_detector(model, img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = res\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_result_pyplot(model, img_path, res, score_thr = threshold, out_file = \"/media/quadro/NVME/Mehrab/exps/outputs/output.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/media/quadro/NVME/Mehrab/datasets/bank_statements/bank_asia.jpg', '/media/quadro/NVME/Mehrab/datasets/bank_statements/bank_asia_2.jpg', '/media/quadro/NVME/Mehrab/datasets/bank_statements/islami_bank.jpg', '/media/quadro/NVME/Mehrab/datasets/bank_statements/islami_bank_blur.jpg', '/media/quadro/NVME/Mehrab/datasets/bank_statements/national_bank.jpg', '/media/quadro/NVME/Mehrab/datasets/bank_statements/sonali_bank.jpg', '/media/quadro/NVME/Mehrab/datasets/bank_statements/sonali_bank_rotated.jpg', '/media/quadro/NVME/Mehrab/datasets/bank_statements/moblie_banking.jpeg', '/media/quadro/NVME/Mehrab/datasets/bank_statements/united_commercial_bank.png']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "folder_path = '/media/quadro/NVME/Mehrab/datasets/bank_statements'\n",
    "image_extensions = ['jpg', 'jpeg', 'png', 'gif', 'bmp']  # Add more if needed\n",
    "\n",
    "# Use glob to get a list of image file paths\n",
    "image_paths = []\n",
    "for extension in image_extensions:\n",
    "    pattern = f'{folder_path}/*.{extension}'\n",
    "    image_paths.extend(glob.glob(pattern))\n",
    "\n",
    "print(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " processing  bank_asia.jpg\n",
      "torch.Size([1, 3000, 9]) torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = (5400, 5) batch_labels = (3000,)\n",
      "bbboxes shape  (5400, 5)\n",
      "labels shape  (3000,)\n",
      "bbboxes shape  (3000, 5)\n",
      "labels shape  (3000,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " processing  bank_asia_2.jpg\n",
      "torch.Size([1, 3000, 9]) torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = (5400, 5) batch_labels = (3000,)\n",
      "bbboxes shape  (5400, 5)\n",
      "labels shape  (3000,)\n",
      "bbboxes shape  (3000, 5)\n",
      "labels shape  (3000,)\n",
      " processing  islami_bank.jpg\n",
      "torch.Size([1, 3000, 9]) torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = (5400, 5) batch_labels = (3000,)\n",
      "bbboxes shape  (5400, 5)\n",
      "labels shape  (3000,)\n",
      "bbboxes shape  (3000, 5)\n",
      "labels shape  (3000,)\n",
      " processing  islami_bank_blur.jpg\n",
      "torch.Size([1, 3000, 9]) torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = (5400, 5) batch_labels = (3000,)\n",
      "bbboxes shape  (5400, 5)\n",
      "labels shape  (3000,)\n",
      "bbboxes shape  (3000, 5)\n",
      "labels shape  (3000,)\n",
      " processing  national_bank.jpg\n",
      "torch.Size([1, 3000, 9]) torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = (5400, 5) batch_labels = (3000,)\n",
      "bbboxes shape  (5400, 5)\n",
      "labels shape  (3000,)\n",
      "bbboxes shape  (3000, 5)\n",
      "labels shape  (3000,)\n",
      " processing  sonali_bank.jpg\n",
      "torch.Size([1, 3000, 9]) torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = (5400, 5) batch_labels = (3000,)\n",
      "bbboxes shape  (5400, 5)\n",
      "labels shape  (3000,)\n",
      "bbboxes shape  (3000, 5)\n",
      "labels shape  (3000,)\n",
      " processing  sonali_bank_rotated.jpg\n",
      "torch.Size([1, 3000, 9]) torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = (5400, 5) batch_labels = (3000,)\n",
      "bbboxes shape  (5400, 5)\n",
      "labels shape  (3000,)\n",
      "bbboxes shape  (3000, 5)\n",
      "labels shape  (3000,)\n",
      " processing  moblie_banking.jpeg\n",
      "torch.Size([1, 3000, 9]) torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = (5400, 5) batch_labels = (3000,)\n",
      "bbboxes shape  (5400, 5)\n",
      "labels shape  (3000,)\n",
      "bbboxes shape  (3000, 5)\n",
      "labels shape  (3000,)\n",
      " processing  united_commercial_bank.png\n",
      "torch.Size([1, 3000, 9]) torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = (5400, 5) batch_labels = (3000,)\n",
      "bbboxes shape  (5400, 5)\n",
      "labels shape  (3000,)\n",
      "bbboxes shape  (3000, 5)\n",
      "labels shape  (3000,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for img_path in image_paths:\n",
    "    file_name = os.path.basename(img_path)\n",
    "    \n",
    "    print(\" processing \", file_name)\n",
    "    res = inference_detector(model, img_path)\n",
    "    show_result_pyplot(model, img_path, res, score_thr = threshold, out_file = f\"/media/quadro/NVME/Mehrab/datasets/bank_statements/outputs/{file_name}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_algo2 = algo2_result_to_aligned_result(res1, threshold=threshold, r=0.2)\n",
    "res_dbscan = dbscan_result_to_aligned_result(res1, threshold=threshold)\n",
    "_res_algo2 = res_algo2\n",
    "_res_dbscan = res_dbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_result_pyplot(model, img_path, _res_algo2, score_thr = threshold, out_file = \"/media/quadro/NVME/Mehrab/exps/outputs/output_algo2.jpg\")\n",
    "show_result_pyplot(model, img_path, _res_dbscan, score_thr = threshold, out_file = \"/media/quadro/NVME/Mehrab/exps/outputs/output_dbscan.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples =  27\n",
      "sorted_confident_x = [-1, 101, 218, 347, 507, 707]\n",
      "sorted_confident_y = [678]\n"
     ]
    }
   ],
   "source": [
    "result = res\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "boxes = result[0]\n",
    "confident_boxes = boxes[boxes[:, 4] > threshold]\n",
    "count_confident_boxes = confident_boxes.shape[0]\n",
    "\n",
    "updated_confident_boxes=confident_boxes\n",
    "\n",
    "X = confident_boxes[:, [0, 2]].flatten()\n",
    "Y = confident_boxes[:, [1, 3]].flatten()\n",
    "\n",
    "X_scaled = MinMaxScaler().fit_transform(X.reshape((-1, 1)))\n",
    "Y_scaled = MinMaxScaler().fit_transform(Y.reshape((-1, 1)))\n",
    "\n",
    "min_samples = int(np.sqrt(count_confident_boxes) / 2)\n",
    "print(\"min_samples = \", min_samples)\n",
    "clustering_X = DBSCAN(eps=0.01, min_samples=min_samples).fit_predict(X_scaled)\n",
    "clustering_Y = DBSCAN(eps=0.01, min_samples=min_samples).fit_predict(Y_scaled)\n",
    "\n",
    "labels_X = set(clustering_X)\n",
    "labels_Y = set(clustering_Y)\n",
    "\n",
    "\n",
    "img = Image.open(img_path)\n",
    "draw = ImageDraw.Draw(img)\n",
    "colors = [(255,0,0), (255,255,0), (255,0,255)]\n",
    "width = 5\n",
    "\n",
    "x_correct = []\n",
    "y_correct = []\n",
    "for x in labels_X:\n",
    "    if x != -1:\n",
    "        x_mean = int(np.mean(X[np.array(clustering_X) == x]))\n",
    "        # print(f\"x_label = {x}, x_mean = {x_mean}\")\n",
    "        x_correct.append(x_mean)\n",
    "    \n",
    "for y in labels_Y:\n",
    "    if y != -1:\n",
    "        y_mean = int(np.mean(Y[np.array(clustering_Y) == y]))\n",
    "        # print(f\"y_label = {y}, y_mean = {y_mean}\")\n",
    "        y_correct.append(y_mean)\n",
    "\n",
    "for x in labels_X:\n",
    "    if x != -1:\n",
    "        x_mean = int(np.mean(X[np.array(clustering_X) == x]))\n",
    "        endpoints = (x_mean, max(y_correct)), (x_mean, min(y_correct))\n",
    "        draw.line(endpoints, fill=colors[0], width=width)\n",
    "for y in labels_Y:\n",
    "    if y != -1:\n",
    "        y_mean = int(np.mean(Y[np.array(clustering_Y) == y]))\n",
    "        endpoints = (max(x_correct), y_mean), (min(x_correct), y_mean)\n",
    "        draw.line(endpoints, fill=colors[0], width=width)\n",
    "    \n",
    "print(f\"sorted_confident_x = {sorted(x_correct)}\")\n",
    "print(f\"sorted_confident_y = {sorted(y_correct)}\")\n",
    "\n",
    "img.save(\"/media/quadro/NVME/Mehrab/exps/outputs/output_lines.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
