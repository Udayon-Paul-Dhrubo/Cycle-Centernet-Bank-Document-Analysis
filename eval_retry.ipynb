{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quadro/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "from utils import *\n",
    "import mmcv\n",
    "import torch\n",
    "import wandb\n",
    "from mmcv import Config\n",
    "from mmcv.parallel import MMDistributedDataParallel\n",
    "from mmdet.apis import set_random_seed, train_detector\n",
    "from mmdet.apis import init_detector, inference_detector, show_result_pyplot\n",
    "from algo2_result_to_aligned_result import algo2_result_to_aligned_result\n",
    "# Let's take a look at the dataset image\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from xml_to_np import xml_to_np, all_xml_to_np\n",
    "from AP import calc_iou_individual, get_single_image_results\n",
    "from soft_nms import py_cpu_softnms\n",
    "from dbscan_result_to_aligned_result import dbscan_result_to_aligned_result\n",
    "from AP import calc_iou_individual\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from utils import print_LC, detect_quads\n",
    "import subprocess\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_file=\"/media/quadro/NVME/Mehrab/exps/32_quad_long_retry/latest.pth\"\n",
    "config_file='/media/quadro/NVME/Mehrab/Current_Experiment/config.py'\n",
    "\n",
    "img_path=\"/media/quadro/NVME/Mehrab/datasets/bank_statements/united_commercial_bank.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-24 19:56:55,824 - root - INFO - ModulatedDeformConvPack neck.deconv_layers.0.conv is upgraded to version 2.\n",
      "2024-02-24 19:56:55,827 - root - INFO - ModulatedDeformConvPack neck.deconv_layers.2.conv is upgraded to version 2.\n",
      "2024-02-24 19:56:55,829 - root - INFO - ModulatedDeformConvPack neck.deconv_layers.4.conv is upgraded to version 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: /media/quadro/NVME/Mehrab/exps/32_quad_long_retry/latest.pth\n",
      "torch.Size([1, 3000, 9]) torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = (5400, 5) batch_labels = (3000,)\n",
      "bbboxes shape  (5400, 5)\n",
      "labels shape  (3000,)\n",
      "bbboxes shape  (3000, 5)\n",
      "labels shape  (3000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[394, 825, 475, 825, 478],\n",
       "        [477, 581, 535, 581, 535],\n",
       "        [620, 793, 723, 778, 723],\n",
       "        ...,\n",
       "        [459, 535, 551, 522, 550],\n",
       "        [135, 306, 258, 318, 243],\n",
       "        [211, 529, 346, 533, 358]])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_quads(img_path=img_path,\n",
    "             checkpoint_file=checkpoint_file,\n",
    "             config_file=config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=4.91s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-24 19:57:14,864 - root - INFO - ModulatedDeformConvPack neck.deconv_layers.0.conv is upgraded to version 2.\n",
      "2024-02-24 19:57:14,868 - root - INFO - ModulatedDeformConvPack neck.deconv_layers.2.conv is upgraded to version 2.\n",
      "2024-02-24 19:57:14,870 - root - INFO - ModulatedDeformConvPack neck.deconv_layers.4.conv is upgraded to version 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: /media/quadro/NVME/Mehrab/exps/32_quad_long_retry/latest.pth\n"
     ]
    }
   ],
   "source": [
    "cfg = Config.fromfile(config_file)\n",
    "\n",
    "set_random_seed(0, deterministic=False)\n",
    "\n",
    "dataset = build_dataset(cfg.data.test)\n",
    "\n",
    "model = build_detector(cfg.model, train_cfg=cfg.model.test_cfg)#, test_cfg=cfg.model.test_cfg)\n",
    "model.CLASSES = dataset.CLASSES\n",
    "\n",
    "model = init_detector(config_file, checkpoint_file, device=f'cuda:3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/quadro/NVME/Mehrab/datasets/test/images/11e8c54bfc1c398f048045b61d12db94.jpg\n",
      "torch.Size([1, 3000, 9]) torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = (5400, 5) batch_labels = (3000,)\n",
      "bbboxes shape  (5400, 5)\n",
      "labels shape  (3000,)\n",
      "bbboxes shape  (3000, 5)\n",
      "labels shape  (3000,)\n"
     ]
    }
   ],
   "source": [
    "conf_threshold = 0.5\n",
    "iou_threshold = 0.9\n",
    "res = []\n",
    "# for idx in tqdm(range(int(len(dataset)))):\n",
    "idx = 7\n",
    "anno = dataset.get_ann_info(idx=idx)\n",
    "boxes = anno[\"bboxes\"]\n",
    "segm_path = anno[\"seg_map\"]\n",
    "# xml_path = f\"/home/aiarhipov/datasets/WTW-dataset/test/xml/{segm_path[:-4]}.xml\"\n",
    "# img_path = f\"/home/aiarhipov/datasets/WTW-dataset/test/images/{segm_path[:-4]}.jpg\"\n",
    "img_path = f\"/media/quadro/NVME/Mehrab/datasets/test/images/11e8c54bfc1c398f048045b61d12db94.jpg\"\n",
    "xml_path = f\"/media/quadro/NVME/Mehrab/datasets/test/xml/11e8c54bfc1c398f048045b61d12db94.xml\"\n",
    "# img_path = f\"/home/aiarhipov/datasets/WTW-dataset/test/images/1vzhDVZkRiOr9FWYuJP7oQAAACMAAQED.jpg\"\n",
    "# xml_path = f\"/home/aiarhipov/datasets/WTW-dataset/test/xml/1vzhDVZkRiOr9FWYuJP7oQAAACMAAQED.xml\"\n",
    "# img_path = f\"/home/aiarhipov/datasets/WTW-dataset/test/images/mit_google_image_search-10918758-86d8fb6ae7082304fd621df58c68adee00278d96.jpg\"\n",
    "# xml_path = f\"/home/aiarhipov/datasets/WTW-dataset/test/xml/mit_google_image_search-10918758-86d8fb6ae7082304fd621df58c68adee00278d96.xml\"\n",
    "\n",
    "\n",
    "print(img_path)\n",
    "gt_boxes = xml_to_np(xml_path)\n",
    "# print(f\"gt_boxes[0] = {gt_boxes[:5]}\")\n",
    "c\n",
    "# print(pred.shape)\n",
    "# pred = pred[int(len(pred)/2):]\n",
    "# print(f\"pred[0] = {pred[:5]}\")\n",
    "# conf_indexes = py_cpu_softnms(pred[:, :4], pred[:, 4], thresh=0.475, method=2)\n",
    "# print(f\"conf_indexes = {conf_indexes}\")\n",
    "# conf_pred = pred[conf_indexes]\n",
    "# print(f\"conf_pred[0] = {conf_pred[:5]}\")\n",
    "# if conf_pred.shape[0] > 1:\n",
    "#     conf_pred = dbscan_result_to_aligned_result([conf_pred])\n",
    "#     if conf_pred:\n",
    "#         conf_pred = conf_pred[0]\n",
    "#         print(gt_boxes[:, :4].shape)\n",
    "#         print(conf_pred[:, :4].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3000, 9]) torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = (5400, 5) batch_labels = (3000,)\n",
      "bbboxes shape  (5400, 5)\n",
      "labels shape  (3000,)\n",
      "bbboxes shape  (3000, 5)\n",
      "labels shape  (3000,)\n",
      "torch.Size([1, 3000, 9]) torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "before in _get_bboxes_single batch_det_bboxes = torch.Size([1, 3000, 9]), batch_labels = torch.Size([1, 3000])\n",
      "torch.Size([3000, 9]) torch.Size([3000])\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import mmcv\n",
    "import numpy as np\n",
    "import torch\n",
    "from mmcv.ops import RoIPool\n",
    "from mmcv.parallel import collate, scatter\n",
    "from mmcv.runner import load_checkpoint\n",
    "\n",
    "from mmdet.core import get_classes\n",
    "from mmdet.datasets import replace_ImageToTensor\n",
    "from mmdet.datasets.pipelines import Compose\n",
    "from mmdet.models import build_detector\n",
    "imgs = img_path\n",
    "if isinstance(imgs, (list, tuple)):\n",
    "    is_batch = True\n",
    "else:\n",
    "    imgs = [imgs]\n",
    "    is_batch = False\n",
    "\n",
    "cfg = model.cfg\n",
    "device = next(model.parameters()).device  # model device\n",
    "\n",
    "if isinstance(imgs[0], np.ndarray):\n",
    "    cfg = cfg.copy()\n",
    "    # set loading pipeline type\n",
    "    cfg.data.test.pipeline[0].type = 'LoadImageFromWebcam'\n",
    "\n",
    "cfg.data.test.pipeline = replace_ImageToTensor(cfg.data.test.pipeline)\n",
    "test_pipeline = Compose(cfg.data.test.pipeline)\n",
    "\n",
    "datas = []\n",
    "for img in imgs:\n",
    "    # prepare data\n",
    "    if isinstance(img, np.ndarray):\n",
    "        # directly add img\n",
    "        data = dict(img=img)\n",
    "    else:\n",
    "        # add information into dict\n",
    "        data = dict(img_info=dict(filename=img), img_prefix=None)\n",
    "    # build the data pipeline\n",
    "    data = test_pipeline(data)\n",
    "    datas.append(data)\n",
    "\n",
    "data = collate(datas, samples_per_gpu=len(imgs))\n",
    "# just get the actual data from DataContainer\n",
    "data['img_metas'] = [img_metas.data[0] for img_metas in data['img_metas']]\n",
    "data['img'] = [img.data[0] for img in data['img']]\n",
    "if next(model.parameters()).is_cuda:\n",
    "    # scatter to specified GPU\n",
    "    data = scatter(data, [device])[0]\n",
    "else:\n",
    "    for m in model.modules():\n",
    "        assert not isinstance(\n",
    "            m, RoIPool\n",
    "        ), 'CPU inference with RoIPool is not supported currently.'\n",
    "\n",
    "# forward the model\n",
    "with torch.no_grad():\n",
    "    results = model(return_loss=False, rescale=True, **data)\n",
    "\n",
    "# model.forward(data['img'], data['img_metas'], return_loss=False)\n",
    "center_heatmap_preds, offset_preds, center2vertex_pred, vertex2center_pred = model.bbox_head(model.extract_feat(data['img'][0]))\n",
    "# gb = model.bbox_head.get_bboxes(center_heatmap_preds, offset_preds, center2vertex_pred, vertex2center_pred, data['img_metas'][0])\n",
    "result_list = []\n",
    "for img_id in range(len(data['img_metas'])):\n",
    "    result_list.append(\n",
    "        model.bbox_head._get_bboxes_single(\n",
    "            center_heatmap_preds[0][img_id : img_id + 1, 0:1, ...],\n",
    "            center2vertex_pred[0][img_id : img_id + 1, ...],\n",
    "            offset_preds[0][img_id : img_id + 1, ...],\n",
    "            data['img_metas'][img_id][0],\n",
    "            rescale=False,\n",
    "            with_nms=False,\n",
    "        )\n",
    "    )\n",
    "print(result_list[0][0].reshape(result_list[0][1].shape[0], -1).shape, result_list[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xml_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mline(img, (quad[\u001b[38;5;241m4\u001b[39m], quad[\u001b[38;5;241m5\u001b[39m]), (quad[\u001b[38;5;241m6\u001b[39m], quad[\u001b[38;5;241m7\u001b[39m]), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), thickness\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     14\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mline(img, (quad[\u001b[38;5;241m6\u001b[39m], quad[\u001b[38;5;241m7\u001b[39m]), (quad[\u001b[38;5;241m0\u001b[39m], quad[\u001b[38;5;241m1\u001b[39m]), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), thickness\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m gt_boxes \u001b[38;5;241m=\u001b[39m all_xml_to_np(\u001b[43mxml_path\u001b[49m)\n\u001b[1;32m     17\u001b[0m gt_boxes \u001b[38;5;241m=\u001b[39m gt_boxes\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m quad \u001b[38;5;129;01min\u001b[39;00m gt_boxes:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xml_path' is not defined"
     ]
    }
   ],
   "source": [
    "quads = result_list[0][0].reshape(result_list[0][1].shape[0], -1)[:25]\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from mmdet.models.utils.gaussian_target import get_local_maximum, get_topk_from_heatmap, transpose_and_gather_feat\n",
    "\n",
    "# im = Image.open(\"/home/aiarhipov/centernet/imgs/tmp.jpg\")\n",
    "img = cv2.imread(img_path)\n",
    "quads = quads.cpu().detach().numpy().astype(int)\n",
    "for quad in quads:\n",
    "    cv2.line(img, (quad[0], quad[1]), (quad[2], quad[3]), (0, 255, 0), thickness=1)\n",
    "    cv2.line(img, (quad[2], quad[3]), (quad[4], quad[5]), (0, 255, 0), thickness=1)\n",
    "    cv2.line(img, (quad[4], quad[5]), (quad[6], quad[7]), (0, 255, 0), thickness=1)\n",
    "    cv2.line(img, (quad[6], quad[7]), (quad[0], quad[1]), (0, 255, 0), thickness=1)\n",
    "    \n",
    "gt_boxes = all_xml_to_np(xml_path)\n",
    "gt_boxes = gt_boxes.astype(int)\n",
    "for quad in gt_boxes:\n",
    "    cv2.line(img, (quad[0], quad[1]), (quad[2], quad[3]), (255, 0, 0), thickness=1)\n",
    "    cv2.line(img, (quad[2], quad[3]), (quad[4], quad[5]), (255, 0, 0), thickness=1)\n",
    "    cv2.line(img, (quad[4], quad[5]), (quad[6], quad[7]), (255, 0, 0), thickness=1)\n",
    "    cv2.line(img, (quad[6], quad[7]), (quad[0], quad[1]), (255, 0, 0), thickness=1)\n",
    "    \n",
    "\n",
    "height, width = center_heatmap_preds[0].shape[2:]\n",
    "inp_h, inp_w = img.shape[:2]\n",
    "\n",
    "center_heatmap_pred = get_local_maximum(center_heatmap_preds[0][:, 1:2, ...], kernel=1)\n",
    "\n",
    "*batch_dets, topk_ys, topk_xs = get_topk_from_heatmap(center_heatmap_pred, k=1000)\n",
    "batch_scores, batch_index, batch_topk_labels = batch_dets\n",
    "offset = transpose_and_gather_feat(offset_preds[0], batch_index)\n",
    "# print(topk_xs, topk_ys)\n",
    "\n",
    "topk_xs = topk_xs + offset[..., 0]\n",
    "topk_ys = topk_ys + offset[..., 1]\n",
    "# print(topk_xs, topk_ys)\n",
    "for x, y in zip(topk_xs[0].cpu().detach().numpy(), topk_ys[0].cpu().detach().numpy()):\n",
    "    cv2.circle(img, (int(x * (inp_w / width)), int(y * (inp_h / height))), radius=2, color=(0, 0, 255), thickness=-1)\n",
    "Image.fromarray(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topk_xs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dbscan\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[0;32m----> 3\u001b[0m vertexes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([\u001b[43mtopk_xs\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(), topk_ys[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()])\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m      4\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[1;32m      5\u001b[0m clusters \u001b[38;5;241m=\u001b[39m dbscan(scaler\u001b[38;5;241m.\u001b[39mfit_transform(vertexes), eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.02\u001b[39m, min_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'topk_xs' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import dbscan\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "vertexes = np.vstack([topk_xs[0].cpu().detach().numpy(), topk_ys[0].cpu().detach().numpy()]).T\n",
    "scaler = MinMaxScaler()\n",
    "clusters = dbscan(scaler.fit_transform(vertexes), eps=0.02, min_samples=2)\n",
    "index, labels = clusters\n",
    "for label in np.unique(labels):\n",
    "    x, y = vertexes[labels == label].mean(axis=0)\n",
    "    cv2.circle(img, (int(x * (inp_w / width)), int(y * (inp_h / height))), radius=4, color=(0, 255, 255), thickness=-1)\n",
    "Image.fromarray(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
