{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!lsof -i :29500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m1805109\u001b[0m (\u001b[33mthesis_bank_document\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m1805109\u001b[0m (\u001b[33mthesis_bank_document\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "/media/quadro/NVME/Mehrab/Current_Experiment/mmdet/utils/setup_env.py:17: UserWarning: Multi-processing start method `fork` is different from the previous setting `spawn`.It will be force set to `fork`. You can change this behavior by changing `mp_start_method` in your config.\n",
      "  warnings.warn(\n",
      "/media/quadro/NVME/Mehrab/Current_Experiment/mmdet/utils/setup_env.py:17: UserWarning: Multi-processing start method `fork` is different from the previous setting `spawn`.It will be force set to `fork`. You can change this behavior by changing `mp_start_method` in your config.\n",
      "  warnings.warn(\n",
      "/media/quadro/NVME/Mehrab/Current_Experiment/mmdet/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n",
      "  warnings.warn(\n",
      "loading annotations into memory...\n",
      "/media/quadro/NVME/Mehrab/Current_Experiment/mmdet/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n",
      "  warnings.warn(\n",
      "loading annotations into memory...\n",
      "Done (t=14.74s)\n",
      "creating index...\n",
      "Done (t=14.77s)\n",
      "creating index...\n",
      "index created!\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "loading annotations into memory...\n",
      "Done (t=4.44s)\n",
      "creating index...\n",
      "Done (t=4.45s)\n",
      "creating index...\n",
      "index created!\n",
      "index created!\n",
      "2024-01-22 12:56:37,222 - mmdet - INFO - Training with 2 GPU(s) with 8 samples per GPU. The total batch size is 16.\n",
      "2024-01-22 12:56:37,222 - mmdet - INFO - The batch size match the base batch size: 16, will not scaling the LR (0.0025).\n",
      "loading annotations into memory...\n",
      "loading annotations into memory...\n",
      "Done (t=6.25s)\n",
      "creating index...\n",
      "Done (t=6.25s)\n",
      "creating index...\n",
      "index created!\n",
      "index created!\n",
      "2024-01-22 12:56:44,067 - mmdet - INFO - Start running, host: quadro@quadro-Pro-E800-G4-WS950T, work_dir: /media/quadro/NVME/Mehrab/exps/32_quad_long_retry_multigpu\n",
      "2024-01-22 12:56:44,068 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) DistEvalHook                       \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) DistEvalHook                       \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) DistEvalHook                       \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) DistEvalHook                       \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) DistEvalHook                       \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "2024-01-22 12:56:44,068 - mmdet - INFO - workflow: [('train', 1), ('val', 1)], max: 150 epochs\n",
      "2024-01-22 12:56:44,068 - mmdet - INFO - Checkpoints will be saved to /media/quadro/NVME/Mehrab/exps/32_quad_long_retry_multigpu by HardDiskBackend.\n",
      "########\n",
      "{'project': 'CenterNet', 'entity': 'thesis_bank_document', 'name': '32_quad_long_retry_multigpu', 'dir': '/media/quadro/NVME/Mehrab/exps/wandb', 'tags': ['local_maximum_kernel=1', '1hm', '150_epoch', '0.0025_lr', '150_eval_lag', '1_chkpt_lag', 'DLANetMMDet3D_backbone', '16_batch']}\n",
      "########\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.2 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/media/quadro/NVME/Mehrab/exps/wandb/wandb/run-20240122_125644-qit70ctr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m32_quad_long_retry_multigpu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/thesis_bank_document/CenterNet\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/thesis_bank_document/CenterNet/runs/qit70ctr\u001b[0m\n",
      "2024-01-22 12:56:49,531 - mmdet - WARNING - No meta information found in the runner. \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   12 of 12 files downloaded.  \n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "2024-01-22 13:06:55,408 - mmdet - INFO - Epoch [1][343/687]\tlr: 8.566e-04, eta: 2 days, 1:37:47, time: 1.740, data_time: 0.018, memory: 2516, loss_center_heatmap: 8.9778, loss_offset: 0.3367, loss_c2v: 3.7332, loss_v2c: 1.8805, loss: 14.9282, grad_norm: 68.8156\n",
      "Traceback (most recent call last):\n",
      "  File \"train3.py\", line 60, in <module>\n",
      "    train_detector(model, datasets, cfg, distributed=True, validate=True)\n",
      "  File \"/media/quadro/NVME/Mehrab/Current_Experiment/mmdet/apis/train.py\", line 244, in train_detector\n",
      "    runner.run(data_loaders, cfg.workflow)\n",
      "  File \"/media/quadro/NVME/afnan/conda/openmmlab/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py\", line 136, in run\n",
      "    epoch_runner(data_loaders[i], **kwargs)\n",
      "  File \"/media/quadro/NVME/afnan/conda/openmmlab/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py\", line 53, in train\n",
      "    self.run_iter(data_batch, train_mode=True, **kwargs)\n",
      "  File \"/media/quadro/NVME/afnan/conda/openmmlab/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py\", line 31, in run_iter\n",
      "    outputs = self.model.train_step(data_batch, self.optimizer,\n",
      "  File \"/media/quadro/NVME/afnan/conda/openmmlab/lib/python3.8/site-packages/mmcv/parallel/distributed.py\", line 63, in train_step\n",
      "    output = self.module.train_step(*inputs[0], **kwargs[0])\n",
      "  File \"/media/quadro/NVME/Mehrab/Current_Experiment/mmdet/models/detectors/base.py\", line 249, in train_step\n",
      "    loss, log_vars = self._parse_losses(losses)\n",
      "  File \"/media/quadro/NVME/Mehrab/Current_Experiment/mmdet/models/detectors/base.py\", line 208, in _parse_losses\n",
      "    assert log_var_length == len(log_vars) * dist.get_world_size(), \\\n",
      "AssertionError: loss log variables are different across GPUs!\n",
      "rank 0 len(log_vars): 4 keys: loss_center_heatmap,loss_offset,loss_c2v,loss_v2c\n",
      "Traceback (most recent call last):\n",
      "  File \"train3.py\", line 60, in <module>\n",
      "    train_detector(model, datasets, cfg, distributed=True, validate=True)\n",
      "  File \"/media/quadro/NVME/Mehrab/Current_Experiment/mmdet/apis/train.py\", line 244, in train_detector\n",
      "    runner.run(data_loaders, cfg.workflow)\n",
      "  File \"/media/quadro/NVME/afnan/conda/openmmlab/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py\", line 136, in run\n",
      "    epoch_runner(data_loaders[i], **kwargs)\n",
      "  File \"/media/quadro/NVME/afnan/conda/openmmlab/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py\", line 53, in train\n",
      "    self.run_iter(data_batch, train_mode=True, **kwargs)\n",
      "  File \"/media/quadro/NVME/afnan/conda/openmmlab/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py\", line 31, in run_iter\n",
      "    outputs = self.model.train_step(data_batch, self.optimizer,\n",
      "  File \"/media/quadro/NVME/afnan/conda/openmmlab/lib/python3.8/site-packages/mmcv/parallel/distributed.py\", line 63, in train_step\n",
      "    output = self.module.train_step(*inputs[0], **kwargs[0])\n",
      "  File \"/media/quadro/NVME/Mehrab/Current_Experiment/mmdet/models/detectors/base.py\", line 249, in train_step\n",
      "    loss, log_vars = self._parse_losses(losses)\n",
      "  File \"/media/quadro/NVME/Mehrab/Current_Experiment/mmdet/models/detectors/base.py\", line 208, in _parse_losses\n",
      "    assert log_var_length == len(log_vars) * dist.get_world_size(), \\\n",
      "AssertionError: loss log variables are different across GPUs!\n",
      "rank 1 len(log_vars): 4 keys: loss_center_heatmap,loss_offset,loss_c2v,loss_v2c\n",
      "Killing subprocess 415975\n",
      "Killing subprocess 415976\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/quadro/NVME/afnan/conda/openmmlab/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/media/quadro/NVME/afnan/conda/openmmlab/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/media/quadro/NVME/afnan/conda/openmmlab/lib/python3.8/site-packages/torch/distributed/launch.py\", line 340, in <module>\n",
      "    main()\n",
      "  File \"/media/quadro/NVME/afnan/conda/openmmlab/lib/python3.8/site-packages/torch/distributed/launch.py\", line 326, in main\n",
      "    sigkill_handler(signal.SIGTERM, None)  # not coming back\n",
      "  File \"/media/quadro/NVME/afnan/conda/openmmlab/lib/python3.8/site-packages/torch/distributed/launch.py\", line 301, in sigkill_handler\n",
      "    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['/media/quadro/NVME/afnan/conda/openmmlab/bin/python', '-u', 'train3.py', '--local_rank=1', '--launcher', 'pytorch']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "!bash dist_train.sh 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m1805109\u001b[0m (\u001b[33mthesis_bank_document\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m1805109\u001b[0m (\u001b[33mthesis_bank_document\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m1805109\u001b[0m (\u001b[33mthesis_bank_document\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "/media/quadro/NVME/Mehrab/Current_Experiment/mmdet/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n",
      "  warnings.warn(\n",
      "/media/quadro/NVME/Mehrab/Current_Experiment/mmdet/utils/setup_env.py:48: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.\n",
      "  warnings.warn(\n",
      "2024-01-22 15:34:07,476 - mmdet - INFO - Environment info:\n",
      "------------------------------------------------------------\n",
      "sys.platform: linux\n",
      "Python: 3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]\n",
      "CUDA available: True\n",
      "GPU 0,1,2,3: Quadro RTX 5000\n",
      "CUDA_HOME: /home/quadro/anaconda3\n",
      "NVCC: Cuda compilation tools, release 11.6, V11.6.124\n",
      "GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\n",
      "PyTorch: 1.8.1+cu101\n",
      "PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v1.7.0 (Git Hash 7aed236906b1f7a05c0917e5257a1af05e9ff683)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 10.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70\n",
      "  - CuDNN 7.6.3\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=10.1, CUDNN_VERSION=7.6.3, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.8.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, \n",
      "\n",
      "TorchVision: 0.9.1+cu101\n",
      "OpenCV: 4.8.1\n",
      "MMCV: 1.6.2\n",
      "MMCV Compiler: GCC 7.3\n",
      "MMCV CUDA Compiler: 10.1\n",
      "MMDetection: 2.25.3+4f1648f\n",
      "------------------------------------------------------------\n",
      "\n",
      "2024-01-22 15:34:07,826 - mmdet - INFO - Distributed training: True\n",
      "2024-01-22 15:34:08,144 - mmdet - INFO - Config:\n",
      "TEST_NAME = '32_quad_long_retry_multigpu'\n",
      "EVAL_LAG = 150\n",
      "CHECKPOINT_LAG = 1\n",
      "EPOCHS = 150\n",
      "BACKBONE = 'DLANetMMDet3D'\n",
      "NUM_GPUS = 2\n",
      "BATCH = 16\n",
      "LR = 0.0025\n",
      "local_maximum_kernel = 1\n",
      "ITER_PERIOD = 2\n",
      "TAGS = [\n",
      "    'local_maximum_kernel=1', '1hm', '150_epoch', '0.0025_lr', '150_eval_lag',\n",
      "    '1_chkpt_lag', 'DLANetMMDet3D_backbone', '16_batch'\n",
      "]\n",
      "dataset_type = 'CocoDataset'\n",
      "data_root = '/media/quadro/NVME/Mehrab/datasets/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[103.53, 116.28, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\n",
      "data = dict(\n",
      "    samples_per_gpu=8,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='/media/quadro/NVME/Mehrab/datasets/train/train_4x10.json',\n",
      "        img_prefix='train/images/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='LoadImageFromFile', to_float32=True, color_type='color'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                type='PhotoMetricDistortion',\n",
      "                brightness_delta=32,\n",
      "                contrast_range=(0.5, 1.5),\n",
      "                saturation_range=(0.5, 1.5),\n",
      "                hue_delta=18),\n",
      "            dict(\n",
      "                type='RandomCenterCropPad',\n",
      "                crop_size=(512, 512),\n",
      "                ratios=(0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3),\n",
      "                mean=[0, 0, 0],\n",
      "                std=[1, 1, 1],\n",
      "                to_rgb=True,\n",
      "                test_pad_mode=None),\n",
      "            dict(type='Resize', img_scale=(512, 512), keep_ratio=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[103.53, 116.28, 123.675],\n",
      "                std=[1.0, 1.0, 1.0],\n",
      "                to_rgb=False),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ],\n",
      "        data_root='/media/quadro/NVME/Mehrab/datasets/',\n",
      "        classes=('box', )),\n",
      "    val_loss=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='/media/quadro/NVME/Mehrab/datasets/test/test_4x10.json',\n",
      "        img_prefix='test/images/',\n",
      "        pipeline=[\n",
      "            dict(\n",
      "                type='LoadImageFromFile', to_float32=True, color_type='color'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                type='PhotoMetricDistortion',\n",
      "                brightness_delta=32,\n",
      "                contrast_range=(0.5, 1.5),\n",
      "                saturation_range=(0.5, 1.5),\n",
      "                hue_delta=18),\n",
      "            dict(\n",
      "                type='RandomCenterCropPad',\n",
      "                crop_size=(512, 512),\n",
      "                ratios=(0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3),\n",
      "                mean=[0, 0, 0],\n",
      "                std=[1, 1, 1],\n",
      "                to_rgb=True,\n",
      "                test_pad_mode=None),\n",
      "            dict(type='Resize', img_scale=(512, 512), keep_ratio=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[103.53, 116.28, 123.675],\n",
      "                std=[1.0, 1.0, 1.0],\n",
      "                to_rgb=False),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ],\n",
      "        data_root='/media/quadro/NVME/Mehrab/datasets/',\n",
      "        classes=('box', )),\n",
      "    val=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='/media/quadro/NVME/Mehrab/datasets/test/test_4x10.json',\n",
      "        img_prefix='test/images/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile', to_float32=True),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                scale_factor=1.0,\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(\n",
      "                        type='RandomCenterCropPad',\n",
      "                        ratios=None,\n",
      "                        border=None,\n",
      "                        mean=[0, 0, 0],\n",
      "                        std=[1, 1, 1],\n",
      "                        to_rgb=True,\n",
      "                        test_mode=True,\n",
      "                        test_pad_mode=['logical_or', 31],\n",
      "                        test_pad_add_pix=1),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[103.53, 116.28, 123.675],\n",
      "                        std=[1.0, 1.0, 1.0],\n",
      "                        to_rgb=False),\n",
      "                    dict(type='DefaultFormatBundle'),\n",
      "                    dict(\n",
      "                        type='Collect',\n",
      "                        meta_keys=('filename', 'ori_filename', 'ori_shape',\n",
      "                                   'img_shape', 'pad_shape', 'scale_factor',\n",
      "                                   'flip', 'flip_direction', 'img_norm_cfg',\n",
      "                                   'border'),\n",
      "                        keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        data_root='/media/quadro/NVME/Mehrab/datasets/',\n",
      "        classes=('box', )),\n",
      "    test=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='/media/quadro/NVME/Mehrab/datasets/test/test_4x10.json',\n",
      "        img_prefix='test/images/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile', to_float32=True),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                scale_factor=1.0,\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(\n",
      "                        type='RandomCenterCropPad',\n",
      "                        ratios=None,\n",
      "                        border=None,\n",
      "                        mean=[0, 0, 0],\n",
      "                        std=[1, 1, 1],\n",
      "                        to_rgb=True,\n",
      "                        test_mode=True,\n",
      "                        test_pad_mode=['logical_or', 31],\n",
      "                        test_pad_add_pix=1),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[103.53, 116.28, 123.675],\n",
      "                        std=[1.0, 1.0, 1.0],\n",
      "                        to_rgb=False),\n",
      "                    dict(type='DefaultFormatBundle'),\n",
      "                    dict(\n",
      "                        type='Collect',\n",
      "                        meta_keys=('filename', 'ori_filename', 'ori_shape',\n",
      "                                   'img_shape', 'pad_shape', 'scale_factor',\n",
      "                                   'flip', 'flip_direction', 'img_norm_cfg',\n",
      "                                   'border'),\n",
      "                        keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        data_root='/media/quadro/NVME/Mehrab/datasets/',\n",
      "        classes=('box', )))\n",
      "load_from = None\n",
      "resume_from = None\n",
      "model = dict(\n",
      "    type='CenterNet',\n",
      "    backbone=dict(\n",
      "        type='DLANetMMDet3D',\n",
      "        depth=34,\n",
      "        norm_cfg=dict(type='BN'),\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint=\n",
      "            'http://dl.yf.io/dla/models/imagenet/dla34%2Btricks-24a49e58.pth')\n",
      "    ),\n",
      "    neck=dict(\n",
      "        type='CTResNetNeck',\n",
      "        in_channel=512,\n",
      "        num_deconv_filters=(256, 128, 64),\n",
      "        num_deconv_kernels=(4, 4, 4),\n",
      "        use_dcn=True),\n",
      "    bbox_head=dict(\n",
      "        type='CycleCenterNetHead',\n",
      "        in_channel=64,\n",
      "        feat_channel=64,\n",
      "        num_classes=1,\n",
      "        loss_center_heatmap=dict(type='GaussianFocalLoss', loss_weight=1.0),\n",
      "        loss_offset=dict(type='L1Loss', loss_weight=1.0),\n",
      "        loss_c2v=dict(type='L1Loss', loss_weight=1.0),\n",
      "        loss_v2c=dict(type='L1Loss', loss_weight=0.5)),\n",
      "    train_cfg=None,\n",
      "    test_cfg=dict(topk=3000, local_maximum_kernel=1, max_per_img=3000))\n",
      "gpu_ids = range(0, 2)\n",
      "device = 'cuda'\n",
      "optimizer = dict(type='SGD', lr=0.0025, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=150)\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=1000,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[90, 120])\n",
      "auto_scale_lr = dict(enable=True, base_batch_size=16)\n",
      "work_dir = '/media/quadro/NVME/Mehrab/exps/32_quad_long_retry_multigpu'\n",
      "INTERVAL = 343\n",
      "log_config = dict(\n",
      "    interval=343,\n",
      "    hooks=[\n",
      "        dict(type='TextLoggerHook'),\n",
      "        dict(type='TensorboardLoggerHook'),\n",
      "        dict(\n",
      "            type='MMDetWandbHook',\n",
      "            init_kwargs=dict(\n",
      "                project='CenterNet',\n",
      "                entity='thesis_bank_document',\n",
      "                name='32_quad_long_retry_multigpu',\n",
      "                dir='/media/quadro/NVME/Mehrab/exps/wandb',\n",
      "                tags=[\n",
      "                    'local_maximum_kernel=1', '1hm', '150_epoch', '0.0025_lr',\n",
      "                    '150_eval_lag', '1_chkpt_lag', 'DLANetMMDet3D_backbone',\n",
      "                    '16_batch'\n",
      "                ]),\n",
      "            interval=343,\n",
      "            log_checkpoint=True,\n",
      "            log_checkpoint_metadata=False,\n",
      "            num_eval_images=5)\n",
      "    ])\n",
      "log_level = 'INFO'\n",
      "evaluation = dict(interval=150, metric='bbox')\n",
      "checkpoint_config = dict(interval=1, max_keep_ckpts=1)\n",
      "seed = 0\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "workflow = [('train', 1), ('val', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "auto_resume = False\n",
      "\n",
      "2024-01-22 15:34:08,144 - mmdet - INFO - Set random seed to 0, deterministic: False\n",
      "2024-01-22 15:34:08,285 - mmdet - INFO - initialize DLANetMMDet3D with init_cfg {'type': 'Pretrained', 'checkpoint': 'http://dl.yf.io/dla/models/imagenet/dla34%2Btricks-24a49e58.pth'}\n",
      "2024-01-22 15:34:08,286 - mmcv - INFO - load model from: http://dl.yf.io/dla/models/imagenet/dla34%2Btricks-24a49e58.pth\n",
      "2024-01-22 15:34:08,286 - mmcv - INFO - load checkpoint from http path: http://dl.yf.io/dla/models/imagenet/dla34%2Btricks-24a49e58.pth\n",
      "2024-01-22 15:34:11,674 - mmcv - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: fc.weight, fc.bias, level2.root.bn.weight, level2.root.bn.bias, level2.root.bn.running_mean, level2.root.bn.running_var, level2.root.bn.num_batches_tracked, level2.tree1.bn1.weight, level2.tree1.bn1.bias, level2.tree1.bn1.running_mean, level2.tree1.bn1.running_var, level2.tree1.bn1.num_batches_tracked, level2.tree1.bn2.weight, level2.tree1.bn2.bias, level2.tree1.bn2.running_mean, level2.tree1.bn2.running_var, level2.tree1.bn2.num_batches_tracked, level2.tree2.bn1.weight, level2.tree2.bn1.bias, level2.tree2.bn1.running_mean, level2.tree2.bn1.running_var, level2.tree2.bn1.num_batches_tracked, level2.tree2.bn2.weight, level2.tree2.bn2.bias, level2.tree2.bn2.running_mean, level2.tree2.bn2.running_var, level2.tree2.bn2.num_batches_tracked, level3.tree1.root.bn.weight, level3.tree1.root.bn.bias, level3.tree1.root.bn.running_mean, level3.tree1.root.bn.running_var, level3.tree1.root.bn.num_batches_tracked, level3.tree1.tree1.bn1.weight, level3.tree1.tree1.bn1.bias, level3.tree1.tree1.bn1.running_mean, level3.tree1.tree1.bn1.running_var, level3.tree1.tree1.bn1.num_batches_tracked, level3.tree1.tree1.bn2.weight, level3.tree1.tree1.bn2.bias, level3.tree1.tree1.bn2.running_mean, level3.tree1.tree1.bn2.running_var, level3.tree1.tree1.bn2.num_batches_tracked, level3.tree1.tree2.bn1.weight, level3.tree1.tree2.bn1.bias, level3.tree1.tree2.bn1.running_mean, level3.tree1.tree2.bn1.running_var, level3.tree1.tree2.bn1.num_batches_tracked, level3.tree1.tree2.bn2.weight, level3.tree1.tree2.bn2.bias, level3.tree1.tree2.bn2.running_mean, level3.tree1.tree2.bn2.running_var, level3.tree1.tree2.bn2.num_batches_tracked, level3.tree2.root.bn.weight, level3.tree2.root.bn.bias, level3.tree2.root.bn.running_mean, level3.tree2.root.bn.running_var, level3.tree2.root.bn.num_batches_tracked, level3.tree2.tree1.bn1.weight, level3.tree2.tree1.bn1.bias, level3.tree2.tree1.bn1.running_mean, level3.tree2.tree1.bn1.running_var, level3.tree2.tree1.bn1.num_batches_tracked, level3.tree2.tree1.bn2.weight, level3.tree2.tree1.bn2.bias, level3.tree2.tree1.bn2.running_mean, level3.tree2.tree1.bn2.running_var, level3.tree2.tree1.bn2.num_batches_tracked, level3.tree2.tree2.bn1.weight, level3.tree2.tree2.bn1.bias, level3.tree2.tree2.bn1.running_mean, level3.tree2.tree2.bn1.running_var, level3.tree2.tree2.bn1.num_batches_tracked, level3.tree2.tree2.bn2.weight, level3.tree2.tree2.bn2.bias, level3.tree2.tree2.bn2.running_mean, level3.tree2.tree2.bn2.running_var, level3.tree2.tree2.bn2.num_batches_tracked, level4.tree1.root.bn.weight, level4.tree1.root.bn.bias, level4.tree1.root.bn.running_mean, level4.tree1.root.bn.running_var, level4.tree1.root.bn.num_batches_tracked, level4.tree1.tree1.bn1.weight, level4.tree1.tree1.bn1.bias, level4.tree1.tree1.bn1.running_mean, level4.tree1.tree1.bn1.running_var, level4.tree1.tree1.bn1.num_batches_tracked, level4.tree1.tree1.bn2.weight, level4.tree1.tree1.bn2.bias, level4.tree1.tree1.bn2.running_mean, level4.tree1.tree1.bn2.running_var, level4.tree1.tree1.bn2.num_batches_tracked, level4.tree1.tree2.bn1.weight, level4.tree1.tree2.bn1.bias, level4.tree1.tree2.bn1.running_mean, level4.tree1.tree2.bn1.running_var, level4.tree1.tree2.bn1.num_batches_tracked, level4.tree1.tree2.bn2.weight, level4.tree1.tree2.bn2.bias, level4.tree1.tree2.bn2.running_mean, level4.tree1.tree2.bn2.running_var, level4.tree1.tree2.bn2.num_batches_tracked, level4.tree2.root.bn.weight, level4.tree2.root.bn.bias, level4.tree2.root.bn.running_mean, level4.tree2.root.bn.running_var, level4.tree2.root.bn.num_batches_tracked, level4.tree2.tree1.bn1.weight, level4.tree2.tree1.bn1.bias, level4.tree2.tree1.bn1.running_mean, level4.tree2.tree1.bn1.running_var, level4.tree2.tree1.bn1.num_batches_tracked, level4.tree2.tree1.bn2.weight, level4.tree2.tree1.bn2.bias, level4.tree2.tree1.bn2.running_mean, level4.tree2.tree1.bn2.running_var, level4.tree2.tree1.bn2.num_batches_tracked, level4.tree2.tree2.bn1.weight, level4.tree2.tree2.bn1.bias, level4.tree2.tree2.bn1.running_mean, level4.tree2.tree2.bn1.running_var, level4.tree2.tree2.bn1.num_batches_tracked, level4.tree2.tree2.bn2.weight, level4.tree2.tree2.bn2.bias, level4.tree2.tree2.bn2.running_mean, level4.tree2.tree2.bn2.running_var, level4.tree2.tree2.bn2.num_batches_tracked, level5.root.bn.weight, level5.root.bn.bias, level5.root.bn.running_mean, level5.root.bn.running_var, level5.root.bn.num_batches_tracked, level5.tree1.bn1.weight, level5.tree1.bn1.bias, level5.tree1.bn1.running_mean, level5.tree1.bn1.running_var, level5.tree1.bn1.num_batches_tracked, level5.tree1.bn2.weight, level5.tree1.bn2.bias, level5.tree1.bn2.running_mean, level5.tree1.bn2.running_var, level5.tree1.bn2.num_batches_tracked, level5.tree2.bn1.weight, level5.tree2.bn1.bias, level5.tree2.bn1.running_mean, level5.tree2.bn1.running_var, level5.tree2.bn1.num_batches_tracked, level5.tree2.bn2.weight, level5.tree2.bn2.bias, level5.tree2.bn2.running_mean, level5.tree2.bn2.running_var, level5.tree2.bn2.num_batches_tracked\n",
      "\n",
      "missing keys in source state_dict: level2.root.norm.weight, level2.root.norm.bias, level2.root.norm.running_mean, level2.root.norm.running_var, level2.tree1.norm1.weight, level2.tree1.norm1.bias, level2.tree1.norm1.running_mean, level2.tree1.norm1.running_var, level2.tree1.norm2.weight, level2.tree1.norm2.bias, level2.tree1.norm2.running_mean, level2.tree1.norm2.running_var, level2.tree2.norm1.weight, level2.tree2.norm1.bias, level2.tree2.norm1.running_mean, level2.tree2.norm1.running_var, level2.tree2.norm2.weight, level2.tree2.norm2.bias, level2.tree2.norm2.running_mean, level2.tree2.norm2.running_var, level3.tree1.root.norm.weight, level3.tree1.root.norm.bias, level3.tree1.root.norm.running_mean, level3.tree1.root.norm.running_var, level3.tree1.tree1.norm1.weight, level3.tree1.tree1.norm1.bias, level3.tree1.tree1.norm1.running_mean, level3.tree1.tree1.norm1.running_var, level3.tree1.tree1.norm2.weight, level3.tree1.tree1.norm2.bias, level3.tree1.tree1.norm2.running_mean, level3.tree1.tree1.norm2.running_var, level3.tree1.tree2.norm1.weight, level3.tree1.tree2.norm1.bias, level3.tree1.tree2.norm1.running_mean, level3.tree1.tree2.norm1.running_var, level3.tree1.tree2.norm2.weight, level3.tree1.tree2.norm2.bias, level3.tree1.tree2.norm2.running_mean, level3.tree1.tree2.norm2.running_var, level3.tree2.root.norm.weight, level3.tree2.root.norm.bias, level3.tree2.root.norm.running_mean, level3.tree2.root.norm.running_var, level3.tree2.tree1.norm1.weight, level3.tree2.tree1.norm1.bias, level3.tree2.tree1.norm1.running_mean, level3.tree2.tree1.norm1.running_var, level3.tree2.tree1.norm2.weight, level3.tree2.tree1.norm2.bias, level3.tree2.tree1.norm2.running_mean, level3.tree2.tree1.norm2.running_var, level3.tree2.tree2.norm1.weight, level3.tree2.tree2.norm1.bias, level3.tree2.tree2.norm1.running_mean, level3.tree2.tree2.norm1.running_var, level3.tree2.tree2.norm2.weight, level3.tree2.tree2.norm2.bias, level3.tree2.tree2.norm2.running_mean, level3.tree2.tree2.norm2.running_var, level4.tree1.root.norm.weight, level4.tree1.root.norm.bias, level4.tree1.root.norm.running_mean, level4.tree1.root.norm.running_var, level4.tree1.tree1.norm1.weight, level4.tree1.tree1.norm1.bias, level4.tree1.tree1.norm1.running_mean, level4.tree1.tree1.norm1.running_var, level4.tree1.tree1.norm2.weight, level4.tree1.tree1.norm2.bias, level4.tree1.tree1.norm2.running_mean, level4.tree1.tree1.norm2.running_var, level4.tree1.tree2.norm1.weight, level4.tree1.tree2.norm1.bias, level4.tree1.tree2.norm1.running_mean, level4.tree1.tree2.norm1.running_var, level4.tree1.tree2.norm2.weight, level4.tree1.tree2.norm2.bias, level4.tree1.tree2.norm2.running_mean, level4.tree1.tree2.norm2.running_var, level4.tree2.root.norm.weight, level4.tree2.root.norm.bias, level4.tree2.root.norm.running_mean, level4.tree2.root.norm.running_var, level4.tree2.tree1.norm1.weight, level4.tree2.tree1.norm1.bias, level4.tree2.tree1.norm1.running_mean, level4.tree2.tree1.norm1.running_var, level4.tree2.tree1.norm2.weight, level4.tree2.tree1.norm2.bias, level4.tree2.tree1.norm2.running_mean, level4.tree2.tree1.norm2.running_var, level4.tree2.tree2.norm1.weight, level4.tree2.tree2.norm1.bias, level4.tree2.tree2.norm1.running_mean, level4.tree2.tree2.norm1.running_var, level4.tree2.tree2.norm2.weight, level4.tree2.tree2.norm2.bias, level4.tree2.tree2.norm2.running_mean, level4.tree2.tree2.norm2.running_var, level5.root.norm.weight, level5.root.norm.bias, level5.root.norm.running_mean, level5.root.norm.running_var, level5.tree1.norm1.weight, level5.tree1.norm1.bias, level5.tree1.norm1.running_mean, level5.tree1.norm1.running_var, level5.tree1.norm2.weight, level5.tree1.norm2.bias, level5.tree1.norm2.running_mean, level5.tree1.norm2.running_var, level5.tree2.norm1.weight, level5.tree2.norm1.bias, level5.tree2.norm1.running_mean, level5.tree2.norm1.running_var, level5.tree2.norm2.weight, level5.tree2.norm2.bias, level5.tree2.norm2.running_mean, level5.tree2.norm2.running_var\n",
      "\n",
      "loading annotations into memory...\n",
      "loading annotations into memory...\n",
      "Done (t=13.49s)\n",
      "creating index...\n",
      "Done (t=13.51s)\n",
      "creating index...\n",
      "index created!\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "loading annotations into memory...\n",
      "Done (t=8.49s)\n",
      "creating index...\n",
      "Done (t=8.45s)\n",
      "creating index...\n",
      "index created!\n",
      "index created!\n",
      "2024-01-22 15:34:37,549 - mmdet - INFO - Training with 2 GPU(s) with 8 samples per GPU. The total batch size is 16.\n",
      "2024-01-22 15:34:37,549 - mmdet - INFO - The batch size match the base batch size: 16, will not scaling the LR (0.0025).\n",
      "loading annotations into memory...\n",
      "loading annotations into memory...\n",
      "Done (t=6.31s)\n",
      "creating index...\n",
      "Done (t=6.34s)\n",
      "creating index...\n",
      "index created!\n",
      "index created!\n",
      "2024-01-22 15:34:44,486 - mmdet - INFO - Start running, host: quadro@quadro-Pro-E800-G4-WS950T, work_dir: /media/quadro/NVME/Mehrab/exps/32_quad_long_retry_multigpu\n",
      "2024-01-22 15:34:44,486 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) DistEvalHook                       \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) DistEvalHook                       \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) DistEvalHook                       \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) DistEvalHook                       \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) DistEvalHook                       \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(NORMAL      ) DistSamplerSeedHook                \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "2024-01-22 15:34:44,486 - mmdet - INFO - workflow: [('train', 1), ('val', 1)], max: 150 epochs\n",
      "2024-01-22 15:34:44,486 - mmdet - INFO - Checkpoints will be saved to /media/quadro/NVME/Mehrab/exps/32_quad_long_retry_multigpu by HardDiskBackend.\n",
      "########\n",
      "{'project': 'CenterNet', 'entity': 'thesis_bank_document', 'name': '32_quad_long_retry_multigpu', 'dir': '/media/quadro/NVME/Mehrab/exps/wandb', 'tags': ['local_maximum_kernel=1', '1hm', '150_epoch', '0.0025_lr', '150_eval_lag', '1_chkpt_lag', 'DLANetMMDet3D_backbone', '16_batch']}\n",
      "########\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.2 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/media/quadro/NVME/Mehrab/exps/wandb/wandb/run-20240122_153444-2tncr7zv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m32_quad_long_retry_multigpu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/thesis_bank_document/CenterNet\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/thesis_bank_document/CenterNet/runs/2tncr7zv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   12 of 12 files downloaded.  \n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "2024-01-22 15:44:29,365 - mmdet - INFO - Epoch [1][343/687]\tlr: 8.566e-04, eta: 1 day, 23:33:42, time: 1.667, data_time: 0.018, memory: 2518, loss_center_heatmap: 2.2762, loss_offset: 0.3844, loss_c2v: 3.7248, loss_v2c: 1.8622, loss: 8.2476, grad_norm: 5.6319\n",
      "^C\n",
      "Killing subprocess 418057\n",
      "Killing subprocess 418058\n",
      "Main process received SIGINT, exiting\n"
     ]
    }
   ],
   "source": [
    "!bash ./tools/dist_train.sh /media/quadro/NVME/Mehrab/Current_Experiment/config.py 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m1805109\u001b[0m (\u001b[33mthesis_bank_document\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "loading annotations into memory...\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m1805109\u001b[0m (\u001b[33mthesis_bank_document\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "loading annotations into memory...\n",
      "Done (t=14.88s)\n",
      "creating index...\n",
      "Done (t=14.91s)\n",
      "creating index...\n",
      "index created!\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "loading annotations into memory...\n",
      "Done (t=4.49s)\n",
      "creating index...\n",
      "Done (t=4.66s)\n",
      "creating index...\n",
      "index created!\n",
      "index created!\n",
      "2024-01-22 01:06:42,357 - mmdet - INFO - Training with 2 GPU(s) with 8 samples per GPU. The total batch size is 16.\n",
      "2024-01-22 01:06:42,357 - mmdet - INFO - The batch size match the base batch size: 16, will not scaling the LR (0.0025).\n",
      "loading annotations into memory...\n",
      "2024-01-22 01:06:42,457 - mmdet - INFO - Training with 2 GPU(s) with 8 samples per GPU. The total batch size is 16.\n",
      "2024-01-22 01:06:42,457 - mmdet - INFO - The batch size match the base batch size: 16, will not scaling the LR (0.0025).\n",
      "loading annotations into memory...\n",
      "Done (t=6.39s)\n",
      "creating index...\n",
      "Done (t=6.33s)\n",
      "creating index...\n",
      "index created!\n",
      "index created!\n",
      "2024-01-22 01:06:49,334 - mmdet - INFO - Start running, host: quadro@quadro-Pro-E800-G4-WS950T, work_dir: /media/quadro/NVME/Mehrab/exps/32_quad_long_retry_multigpu\n",
      "2024-01-22 01:06:49,334 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "2024-01-22 01:06:49,334 - mmdet - INFO - workflow: [('train', 1), ('val', 1)], max: 150 epochs\n",
      "2024-01-22 01:06:49,334 - mmdet - INFO - Checkpoints will be saved to /media/quadro/NVME/Mehrab/exps/32_quad_long_retry_multigpu by HardDiskBackend.\n",
      "2024-01-22 01:06:49,391 - mmdet - INFO - Start running, host: quadro@quadro-Pro-E800-G4-WS950T, work_dir: /media/quadro/NVME/Mehrab/exps/32_quad_long_retry_multigpu\n",
      "2024-01-22 01:06:49,392 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      "(VERY_LOW    ) TensorboardLoggerHook              \n",
      "(VERY_LOW    ) MMDetWandbHook                     \n",
      " -------------------- \n",
      "2024-01-22 01:06:49,392 - mmdet - INFO - workflow: [('train', 1), ('val', 1)], max: 150 epochs\n",
      "2024-01-22 01:06:49,392 - mmdet - INFO - Checkpoints will be saved to /media/quadro/NVME/Mehrab/exps/32_quad_long_retry_multigpu by HardDiskBackend.\n",
      "########\n",
      "{'project': 'CenterNet', 'entity': 'thesis_bank_document', 'name': '32_quad_long_retry_multigpu', 'dir': '/media/quadro/NVME/Mehrab/exps/wandb', 'tags': ['local_maximum_kernel=1', '1hm', '150_epoch', '0.0025_lr', '150_eval_lag', '1_chkpt_lag', 'DLANetMMDet3D_backbone', '16_batch']}\n",
      "########\n",
      "########\n",
      "{'project': 'CenterNet', 'entity': 'thesis_bank_document', 'name': '32_quad_long_retry_multigpu', 'dir': '/media/quadro/NVME/Mehrab/exps/wandb', 'tags': ['local_maximum_kernel=1', '1hm', '150_epoch', '0.0025_lr', '150_eval_lag', '1_chkpt_lag', 'DLANetMMDet3D_backbone', '16_batch']}\n",
      "########\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.2 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/media/quadro/NVME/Mehrab/exps/wandb/wandb/run-20240122_010649-0t52wky3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m32_quad_long_retry_multigpu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/thesis_bank_document/CenterNet\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/thesis_bank_document/CenterNet/runs/0t52wky3\u001b[0m\n",
      "2024-01-22 01:06:54,002 - mmdet - WARNING - No meta information found in the runner. \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.2 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/media/quadro/NVME/Mehrab/exps/wandb/wandb/run-20240122_010649-we6luy7j\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33m32_quad_long_retry_multigpu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/thesis_bank_document/CenterNet\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/thesis_bank_document/CenterNet/runs/we6luy7j\u001b[0m\n",
      "2024-01-22 01:06:54,050 - mmdet - WARNING - No meta information found in the runner. \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   12 of 12 files downloaded.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   12 of 12 files downloaded.  \n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 47, in <module>\n",
      "    train_detector(model, datasets, cfg, distributed=False, validate=val)\n",
      "  File \"/media/quadro/NVME/Mehrab/Current_Experiment/mmdet/apis/train.py\", line 244, in train_detector\n",
      "    runner.run(data_loaders, cfg.workflow)\n",
      "  File \"/media/quadro/NVME/afnan/conda/openmmlab/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py\", line 136, in run\n",
      "    epoch_runner(data_loaders[i], **kwargs)\n",
      "  File \"/media/quadro/NVME/afnan/conda/openmmlab/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py\", line 53, in train\n",
      "    self.run_iter(data_batch, train_mode=True, **kwargs)\n",
      "  File \"/media/quadro/NVME/afnan/conda/openmmlab/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py\", line 31, in run_iter\n",
      "    outputs = self.model.train_step(data_batch, self.optimizer,\n",
      "  File \"/media/quadro/NVME/afnan/conda/openmmlab/lib/python3.8/site-packages/mmcv/parallel/data_parallel.py\", line 64, in train_step\n",
      "    assert len(self.device_ids) == 1, \\\n",
      "AssertionError: MMDataParallel only supports single GPU training, if you need to train with multiple GPUs, please use MMDistributedDataParallel instead.\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 47, in <module>\n",
      "    train_detector(model, datasets, cfg, distributed=False, validate=val)\n",
      "  File \"/media/quadro/NVME/Mehrab/Current_Experiment/mmdet/apis/train.py\", line 244, in train_detector\n",
      "    runner.run(data_loaders, cfg.workflow)\n",
      "  File \"/media/quadro/NVME/afnan/conda/openmmlab/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py\", line 136, in run\n",
      "    epoch_runner(data_loaders[i], **kwargs)\n",
      "  File \"/media/quadro/NVME/afnan/conda/openmmlab/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py\", line 53, in train\n",
      "    self.run_iter(data_batch, train_mode=True, **kwargs)\n",
      "  File \"/media/quadro/NVME/afnan/conda/openmmlab/lib/python3.8/site-packages/mmcv/runner/epoch_based_runner.py\", line 31, in run_iter\n",
      "    outputs = self.model.train_step(data_batch, self.optimizer,\n",
      "  File \"/media/quadro/NVME/afnan/conda/openmmlab/lib/python3.8/site-packages/mmcv/parallel/data_parallel.py\", line 64, in train_step\n",
      "    assert len(self.device_ids) == 1, \\\n",
      "AssertionError: MMDataParallel only supports single GPU training, if you need to train with multiple GPUs, please use MMDistributedDataParallel instead.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33m32_quad_long_retry_multigpu\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/thesis_bank_document/CenterNet/runs/0t52wky3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ô∏è‚ö° View job at \u001b[34m\u001b[4mhttps://wandb.ai/thesis_bank_document/CenterNet/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEzMjM2NDA4Nw==/version_details/v1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m/media/quadro/NVME/Mehrab/exps/wandb/wandb/run-20240122_010649-0t52wky3/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33m32_quad_long_retry_multigpu\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/thesis_bank_document/CenterNet/runs/we6luy7j\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ô∏è‚ö° View job at \u001b[34m\u001b[4mhttps://wandb.ai/thesis_bank_document/CenterNet/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjEzMjM2NDA4Nw==/version_details/v1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m/media/quadro/NVME/Mehrab/exps/wandb/wandb/run-20240122_010649-we6luy7j/logs\u001b[0m\n",
      "Killing subprocess 399276\n",
      "Killing subprocess 399277\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/quadro/NVME/afnan/conda/openmmlab/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/media/quadro/NVME/afnan/conda/openmmlab/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/media/quadro/NVME/afnan/conda/openmmlab/lib/python3.8/site-packages/torch/distributed/launch.py\", line 340, in <module>\n",
      "    main()\n",
      "  File \"/media/quadro/NVME/afnan/conda/openmmlab/lib/python3.8/site-packages/torch/distributed/launch.py\", line 326, in main\n",
      "    sigkill_handler(signal.SIGTERM, None)  # not coming back\n",
      "  File \"/media/quadro/NVME/afnan/conda/openmmlab/lib/python3.8/site-packages/torch/distributed/launch.py\", line 301, in sigkill_handler\n",
      "    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)\n",
      "subprocess.CalledProcessError: Command '['/media/quadro/NVME/afnan/conda/openmmlab/bin/python', '-u', 'train.py', '--local_rank=1']' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "!python -m torch.distributed.launch --nproc_per_node=2 --master_port=29500 train.py\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
